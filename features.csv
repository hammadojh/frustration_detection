feature,category,description,example,how_to_model,Human notes,EmoWOZ,EmpatheticDialogues,MELD,DailyDialog,IEMOCAP,EmoContext,GoEmotions,MultiWOZ,SGD,Taskmaster-1,ABCD,Ubuntu,SimDial,DSTC9_Track1,K-EmoCon,valid_dataset,modeled_literature
sentiment_trajectory,linguistic,Change in sentiment polarity over dialogue turns,Sentiment: +0.5 → 0 → -0.4 over three turns,"Run a per-utterance sentiment classifier (e.g., transformer-based). Aggregate last N turns with slope, delta, and moving average features.",Nice. Detection is one thing. It can be used for future prediction. ,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zuters & Leonova (2020) use adaptive vocabulary construction for frustration intensity trajectory prediction. Zuters & Leonova (2022) model turn-level frustration in customer support tweets. Hernandez Caralt et al. (2024) detect user frustration in task-oriented dialog systems. Bodigutla et al. (2020) estimate joint turn- and dialogue-level user satisfaction. Chatterjee et al. (2020) predict customer satisfaction using speech and sentiment features.
politeness_level,linguistic,Degree of courteous language used,'Please' → 'Just do it' → 'Why is this so hard?',"Apply a politeness classifier (e.g., fine-tuned transformer or rule set based on requests/indirectness). Track average and trend over turns.",Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Arunachalam et al. (2001) detect politeness and frustration in child-machine interactions. Potamianos/Yildirim et al. (2005) detect politeness and frustration states in conversational computer games. Zhou et al. (2022) develop adaptive politeness systems. Danescu-Niculescu-Mizil et al. (2013) present computational approaches to politeness modeling.
intent_repetition,linguistic,Repetition of user intents over multiple turns,'I want to book a flight' repeated 3 times,Predict intent per user turn; count consecutive identical intents with minimal slot change. Use semantic similarity to detect paraphrases.,Good,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Hough & Schlangen (2015) detect miscommunication through repetitive patterns. Li et al. (2019) analyze abandonment via no-progress events and repetitive attempts. Oraby et al. (2017) model customer frustration through repetitive dialogue acts. Sandbank et al. (2018) detect egregious conversations including repetitive failed attempts.
directness_abruptness,linguistic,Increase in direct or abrupt expressions,'Tell me now' vs earlier 'Can you please...?',"Detect imperatives and shortening: dependency parse for imperative mood, measure average sentence length drop; train a directness classifier.",Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zhang et al. (2018) detect early signs of conversational failure through increasing directness and abruptness. Arunachalam et al. (2001) study frustration language patterns including direct/abrupt expressions.
confusion_lexical_markers,linguistic,"Words indicating confusion (e.g., 'what?', 'why?')","'Still not working', 'What is going on?'",Lexicon + classifier for confusion cues; detect WH-questions with 'still/again' patterns; weight by recency.,Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Lee & Narayanan (2005) detect negative emotions including confusion through lexical markers. Balaraman et al. (2023) handle third position repair including confusion markers in conversational QA. Purver (2018) models miscommunication phenomena including confusion indicators.
hedging_expressions,linguistic,"Uncertainty phrases such as 'maybe', 'I think'",'Maybe I missed something',"Hedge lexicon ('maybe','I think') + contextual classifier; compute ratio of hedged clauses over time.",Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,"Zhang et al. (2018) use hedging expressions as early warning signals for conversational failure, detecting increased uncertainty and politeness cues before breakdown."
negation_frequency,linguistic,"Frequency of negation words (e.g., 'not', 'can't')","'I can't do this', 'Not working'",Dependency-based negation detection (neg tokens) per turn; normalize by length; track rising rate.,Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zuters & Leonova (2020) use negation as lexical signals for frustration intensity modeling. Begovic et al. (2023) study impact of negation on sentiment value as proxy for negative affect. Hutto & Gilbert (2014) incorporate negation heuristics in sentiment analysis for negative emotion detection.
emotion_words,linguistic,"Use of emotionally charged words (e.g., 'annoyed')",'This is so annoying!',"Use emotion lexicons (e.g., NRC) or emotion classifier; compute frequency or score of negative affect terms over time.",Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zuters & Leonova (2022) model frustration through lexical emotion indicators in customer support. Oraby et al. (2017) predict customer frustration and satisfaction using emotionally charged words in dialogue acts.
discourse_markers,linguistic,"Connective words indicating emotion (e.g., 'so?', 'then')","'Okay... but', 'So? What now?'","Count discourse markers from curated list; distinguish adversative ('but', 'however') vs additive; track shift to adversative.",Ok,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Lee & Narayanan (2005) analyze discourse markers for negative emotion detection. Purver (2018) models repair and miscommunication markers in computational discourse analysis.
emphasis_capitalization,linguistic,Use of all caps or repeated punctuation,'WHY is it like this?!',Regex for ALL CAPS tokens and repeated punctuation; exclude proper nouns via POS; compute fraction per turn.,Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Leonova & Zuters (2021) detect frustration using non-lexical features including capitalization and orthographic emphasis. Teh et al. (2015) account for capitalization in sentiment analysis as emotional intensity markers.
exclamation_density,linguistic,Density of exclamation or question marks,'What?! Really?!',Count '!' and '?' per token; include clusters ('?!'); compute rolling average.,Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Leonova & Zuters (2021) use exclamation density as non-lexical frustration cues. Hutto & Gilbert (2014) incorporate exclamation marks as emotional intensity heuristics in VADER sentiment analysis.
sarcasm_indicators,linguistic,"Sarcastic tone or content, if detectable","Yeah right, like *that* helped",Supervised sarcasm detector (context-aware transformer). Treat as uncertain; use probability not hard label; smooth across turns.,Good,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Ghosh et al. (2018) analyze sarcasm using conversation context as negative affect correlate. Zhang et al. (2018) detect sarcasm as predictor of antisocial and negative conversational outcomes.
system_failures,dialogue,Number of times the system fails to respond correctly,"System: 'Sorry, I didn't get that' (3 times)","From text alone: approximate via system apology patterns ('sorry', 'I didn't get that') or explicit error mentions. Prefer system logs for ground truth.",Good,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Sandbank et al. (2017) detect egregious conversations including system failures leading to negative interactions. Ultes et al. (2017) model user dissatisfaction from system failure patterns in dialogue policy estimation.
repeated_turns,dialogue,Repeated attempts by user to achieve the same goal,User tries same request 4 times,"Measure semantic similarity (e.g., SBERT) between current and prior user requests; or unchanged intent with repeated slots.",Good,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Li et al. (2019) analyze abandonment likelihood through consecutive no-progress events and repeated attempts. Sandbank et al. (2018) detect egregious conversations through repetitive turn patterns.
conversation_length,dialogue,Total number of turns in the dialogue,15 total turns in conversation,Simple count of total turns up to now; optionally weighted by user-only turns.,Nice,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Ultes & Schmitt (2015) relate conversation length to interaction quality and user satisfaction. Chowdhury et al. (2016) predict user satisfaction from turn-taking patterns including dialogue length.
user_corrections,dialogue,Turns where the user corrects themselves or the system,"'No, I meant June 5, not July'","Pattern match corrections ('no, I meant', 'actually') + edit distance between adjacent turns to quantify correction magnitude.",Nice,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Hough & Schlangen (2015) detect miscommunication through user correction patterns as indicators of negative dialogue states.
intent_switch_frequency,dialogue,Frequency of switching between different intents,Switch from 'book a hotel' to 'find restaurant',Apply intent classifier; count transitions between distinct intents within a window; normalize by window size.,Nice,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Cai et al. (2020) predict user intents and satisfaction in conversational recommenders using dialogue dynamics features including intent switching patterns.
self_corrections,dialogue,User explicitly revises their own statements,"'Wait, I meant something else'",Same as 'user_corrections' but confined to self-repair within the same turn or immediately next turn; detect 'sorry/actually' markers.,Ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Hough & Schlangen (2015) detect miscommunication through self-correction patterns as indicators of dialogue breakdown.
confirmation_count,dialogue,Number of times the system asks for confirmation,'Did you say hotel in Paris?' (5 times),"Detect system confirmations in system turns ('did you mean', 'to confirm'); classify confirmation type; sum per window.",Ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Ultes et al. (2017) use confirmation patterns as features for predicting user dissatisfaction in domain-independent dialogue policy estimation.
system_misunderstanding_rate,dialogue,Rate of incorrect system understanding,System replies incorrectly 3 out of 5 times,Approximate with NLI/entailment between user ask and system response (low entailment = misunderstanding). Prefer NLU confusion matrix if available.,Ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Hough & Schlangen (2015) detect miscommunication through system misunderstanding patterns. Sandbank et al. (2018) detect egregious conversations including high system misunderstanding rates. Higashinaka et al. (2017) study dialogue breakdown detection including misunderstanding.
alignment_failures,dialogue,Breakdowns in shared context or goals,User: 'Forget it. This isn’t working',Compute topic/goal alignment using intent + slot coverage overlap; low overlap over several turns ⇒ alignment failure.,Ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,
reply_time_gap,user_behavior,Time between user's replies,20 second delay between turns,Cannot be modeled from text history alone; requires message timestamps to compute inter-reply intervals.,—,no,no,yes,no,yes,no,no,no,no,yes,no,yes,no,no,yes,MELD,
escalation_request,user_behavior,User explicitly asks for escalation or help,'Let me talk to support',"Text classification of escalation phrases ('talk to human', 'agent', 'escalate'); binary flag with recency weighting.",Ok,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,
help_button_usage,user_behavior,User interaction with help features,Clicks 'Need help?' button,Cannot be modeled from text history alone; requires UI telemetry/clickstream for help button events.,—,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,none,
session_dropout,user_behavior,User exits before completing task,"User leaves after 6 turns, no goal reached",Cannot be modeled from text history alone; needs session end state or abandonment logs.,—,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,none,
typing_speed_change,user_behavior,Variation in typing speed during dialogue,"Initial typing fast, then slows down",Cannot be modeled from text history alone; requires keystroke/timestamp telemetry to estimate characters per second.,—,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,none,
re_entry_behavior,user_behavior,User leaves and re-enters session,User closes app and reopens later,Cannot be modeled from text history alone; needs session/user IDs and session start times to detect re-entries.,—,no,no,no,no,yes,no,no,no,no,no,no,yes,no,no,yes,IEMOCAP,
negative_feedback,user_behavior,Explicit negative feedback provided,Thumbs down or negative comment,From text if user explicitly complains/rates; otherwise requires UI rating/feedback telemetry.,Ok,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,
task_complexity,contextual,Estimated complexity of the task,Flight booking with multiple dependencies,Estimate via dialog state: number of required slots/subtasks remaining; classify task difficulty from schema; or learn a complexity regressor.,"Ok, but how can model it?",yes,no,no,no,no,no,no,yes,yes,yes,yes,no,yes,no,no,EmoWOZ,
goal_completion_status,contextual,Whether the user is making progress toward their goal,Bot provides correct city after 5 turns,"From dialog state tracking: proportion of required slots filled or goal conditions met; proxy via success statements in text ('got it', 'done').",Nice.,yes,no,no,no,no,no,no,yes,yes,yes,yes,no,yes,no,no,EmoWOZ,
time_on_task,contextual,Elapsed time since task began,User still active after 10 minutes,Cannot be modeled from text history alone; requires timestamps to accumulate active duration.,#messages,no,no,yes,no,yes,no,no,no,no,yes,no,yes,no,no,yes,MELD,
subgoal_block_count,contextual,Number of blocked subtasks,Cannot add item → cannot pay → cannot confirm,"Count blocked events inferred from phrases ('can't', 'error') or from system error codes; accumulate unique blocked subgoals.",ok,yes,no,no,no,no,no,no,yes,yes,yes,yes,no,yes,no,no,EmoWOZ,
expressed_urgency,contextual,User states urgency or deadline,'I need this done now!',"Urgency lexicon + classifier ('ASAP', 'now', 'urgent'); combine with time expressions; output probability.",ok,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,
device_context,contextual,"Device type (e.g., mobile, desktop)",Mobile vs desktop interface,Cannot be reliably modeled from text unless stated ('on my phone'); prefer client/device metadata.,ok,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,none,
emotion_drift,emotion_dynamics,Shift in emotion over time,Joy → Neutral → Confused → Angry,Run per-turn emotion classifier; compute vector difference between consecutive turns; summarize with slope and cumulative shift.,ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zuters & Leonova (2020) predict change of frustration intensity turn-to-turn. Majumder et al. (2019) detect emotion dynamics including anger/frustration classes through DialogueRNN. Ghosal et al. (2019) model emotion transitions using DialogueGCN.
emotion_volatility,emotion_dynamics,Sudden changes in emotional state,User jumps from happy to furious in 2 turns,Compute variance/entropy over emotion probabilities across last N turns; high variance ⇒ volatility.,ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zuters & Leonova (2022) model turn-level frustration volatility across languages. Survey on Emotion Recognition in Conversations (MDPI 2023) covers emotion volatility and transitions. Fourier GNN MERC (2025 AAAI) models emotion volatility and transitions.
frustration_delay,emotion_dynamics,Delay between problem and frustration expression,"Issue reported at turn 2, anger at turn 6",Detect first obstacle mention time vs first high-probability frustration/anger label; turn difference is the delay.,ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Not found in literature
personality_traits,user_model,"Inferred personality traits (e.g., neuroticism)",High neuroticism inferred from past chats,Infer Big Five from long-term text using pretrained personality models (requires sufficient history across sessions). Use with uncertainty.,ok,no,no,no,no,yes,no,no,no,no,no,no,yes,no,no,yes,IEMOCAP,Peng et al. (2024) predict personality from task-oriented and open-domain dialogue as related factors for user satisfaction. Zhang et al. (2025) study user personality influence on task-oriented dialogue performance and satisfaction.
trust_in_system,user_model,User's level of trust in the system,User asks 'Are you sure?' frequently,"Proxy via acceptance/resistance patterns: counts of challenges ('are you sure?'), refusals, compliance. Optionally include historical success rates (needs logs).",ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Zhang et al. (2025) develop visual analytics for user trust dynamics in conversational agents. Siro et al. (2022) understand user satisfaction with conversational recommenders including trust dimensions.
frustration_tolerance,user_model,Inferred frustration baseline from history,Past 3 sessions show early dropout,Estimate from history: average number of failures/confirmations tolerated before escalation or dropout (needs cross-session logs).,—-,no,no,no,no,yes,no,no,no,no,no,no,yes,no,no,yes,IEMOCAP,Not found in literature
bot_confidence_score,system,Bot's NLU confidence in understanding,Intent confidence: 0.45,Cannot be modeled from text history alone; requires NLU/NLG internal confidence values from the system.,—-,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,none,Ultes et al. (2017) use ASR/NLU confidence scores as features for domain-independent user satisfaction reward estimation in dialogue policy.
response_latency,system,Time taken for system to respond,Bot replies after 5.2 seconds,Cannot be modeled from text history alone; requires server/client timestamps to measure response time.,—-,no,no,yes,no,yes,no,no,no,no,yes,no,yes,no,no,yes,MELD,Choi et al. (2020) predict user satisfaction using timing features including response latency. Azaria et al. (2023) study opposing effects of response time in human-chatbot interaction on user satisfaction.
response_clarity,system,Ambiguity or clarity of bot's response,Bot reply: 'Maybe try that again?',Train a response clarity/ambiguity classifier (or readability metrics + NLI consistency). Use low confidence as higher ambiguity.,ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Ramesh et al. (2020) estimate joint turn- and dialogue-level user satisfaction on multi-domain conversations including turn-level response quality. Bodigutla et al. (2019) evaluate multi-domain dialogue quality via user satisfaction estimation including response quality features.
response_relevance,system,Relevance of system response to user query,User: 'That’s not what I asked for',Compute semantic similarity (embeddings) and NLI entailment between user request and system reply; low similarity/contradiction ⇒ low relevance.,ok,yes,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,EmoWOZ,Sandbank et al. (2017) detect egregious conversations between customers and virtual agents including agent mismatch patterns and low response relevance as indicators of negative interactions.